{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3726bdb-5bf0-4fc0-8a6a-07aa28532f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde859fa-a05d-4bc4-890d-9c96f7d8b984",
   "metadata": {},
   "source": [
    "### Gen catcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc38466-13c7-45bb-b751-29d5ee72669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# imt = cv2.imread('./save_temp/captcha_mst/jpg/27hf8.jpg', 0)\n",
    "# imt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2be6ba4-3a46-4fc9-ac42-3289c924797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/j73w_qnn72b13k4_lvfdxsz57p4wgj/T/ipykernel_1426/3370653664.py:12: DeprecationWarning: QUAD is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.QUAD instead.\n",
      "  from PIL.Image import new as createImage, Image, QUAD, BILINEAR\n",
      "/var/folders/sx/j73w_qnn72b13k4_lvfdxsz57p4wgj/T/ipykernel_1426/3370653664.py:12: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  from PIL.Image import new as createImage, Image, QUAD, BILINEAR\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "    captcha.image\n",
    "    ~~~~~~~~~~~~~\n",
    "\n",
    "    Generate Image CAPTCHAs, just the normal image CAPTCHAs you are using.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import typing as t\n",
    "from PIL.Image import new as createImage, Image, QUAD, BILINEAR\n",
    "from PIL.ImageDraw import Draw, ImageDraw\n",
    "from PIL.ImageFilter import SMOOTH\n",
    "from PIL.ImageFont import FreeTypeFont, truetype\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "ColorTuple = t.Union[t.Tuple[int, int, int], t.Tuple[int, int, int, int]]\n",
    "GEN_CAPTCHA_DIR_ONE = './save_temp/captcha_test/gen_captcha/one_char/'\n",
    "GEN_CAPTCHA_DIR_FIVE = './save_temp/captcha_test/gen_captcha/five_chars/'\n",
    "DEFAULT_FONTS = glob.glob(os.path.join(os.path.join('./save_temp/fonts/selected_fonts/'), \"*\"))\n",
    "\n",
    "class ImageCaptcha:\n",
    "    \"\"\"Create an image CAPTCHA.\n",
    "\n",
    "    Many of the codes are borrowed from wheezy.captcha, with a modification\n",
    "    for memory and developer friendly.\n",
    "\n",
    "    ImageCaptcha has one built-in font, DroidSansMono, which is licensed under\n",
    "    Apache License 2. You should always use your own fonts::\n",
    "\n",
    "        captcha = ImageCaptcha(fonts=['/path/to/A.ttf', '/path/to/B.ttf'])\n",
    "\n",
    "    You can put as many fonts as you like. But be aware of your memory, all of\n",
    "    the fonts are loaded into your memory, so keep them a lot, but not too\n",
    "    many.\n",
    "\n",
    "    :param width: The width of the CAPTCHA image.\n",
    "    :param height: The height of the CAPTCHA image.\n",
    "    :param fonts: Fonts to be used to generate CAPTCHA images.\n",
    "    :param font_sizes: Random choose a font size from this parameters.\n",
    "    \"\"\"\n",
    "    lookup_table: t.List[int] = [int(i * 1.97) for i in range(256)]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            width: int = 160,\n",
    "            height: int = 60,\n",
    "            fonts: t.Optional[t.List[str]] = None,\n",
    "            font_sizes: t.Optional[t.Tuple[int]] = None):\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._fonts = fonts or DEFAULT_FONTS\n",
    "        self._font_sizes = font_sizes or (42, 50, 56)\n",
    "        self._truefonts: t.List[FreeTypeFont] = []\n",
    "\n",
    "    @property\n",
    "    def truefonts(self) -> t.List[FreeTypeFont]:\n",
    "        if self._truefonts:\n",
    "            return self._truefonts\n",
    "        self._truefonts = [\n",
    "            truetype(n, s)\n",
    "            for n in self._fonts\n",
    "            for s in self._font_sizes\n",
    "        ]\n",
    "        return self._truefonts\n",
    "\n",
    "    @staticmethod\n",
    "    def create_noise_curve(image: Image, color: ColorTuple) -> Image:\n",
    "        w, h = image.size\n",
    "        x1 = random.randint(0, int(w / 5))\n",
    "        x2 = random.randint(w - int(w / 5), w)\n",
    "        y1 = random.randint(int(h / 5), h - int(h / 5))\n",
    "        y2 = random.randint(y1, h - int(h / 5))\n",
    "        points = [x1, y1, x2, y2]\n",
    "        end = random.randint(160, 200)\n",
    "        start = random.randint(0, 20)\n",
    "        Draw(image).arc(points, start, end, fill=color)\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def create_noise_dots(\n",
    "            image: Image,\n",
    "            color: ColorTuple,\n",
    "            width: int = 3,\n",
    "            number: int = 30) -> Image:\n",
    "        draw = Draw(image)\n",
    "        w, h = image.size\n",
    "        while number:\n",
    "            x1 = random.randint(0, w)\n",
    "            y1 = random.randint(0, h)\n",
    "            draw.line(((x1, y1), (x1 - 1, y1 - 1)), fill=color, width=width)\n",
    "            number -= 1\n",
    "        return image\n",
    "\n",
    "    def _draw_character(\n",
    "            self,\n",
    "            c: str,\n",
    "            draw: ImageDraw,\n",
    "            color: ColorTuple) -> Image:\n",
    "        font = random.choice(self.truefonts)\n",
    "        _, _, w, h = draw.multiline_textbbox((1, 1), c, font=font)\n",
    "\n",
    "        dx1 = random.randint(0, 4)\n",
    "        dy1 = random.randint(0, 6)\n",
    "        im = createImage('RGBA', (w + dx1, h + dy1))\n",
    "        Draw(im).text((dx1, dy1), c, font=font, fill=color)\n",
    "\n",
    "        # rotate\n",
    "        im = im.crop(im.getbbox())\n",
    "        # im = im.rotate(random.uniform(-30, 30), BILINEAR, expand=True)\n",
    "\n",
    "        # warp\n",
    "        dx2 = w * random.uniform(0.1, 0.3)\n",
    "        dy2 = h * random.uniform(0.2, 0.3)\n",
    "        x1 = int(random.uniform(-dx2, dx2))\n",
    "        y1 = int(random.uniform(-dy2, dy2))\n",
    "        x2 = int(random.uniform(-dx2, dx2))\n",
    "        y2 = int(random.uniform(-dy2, dy2))\n",
    "        w2 = w + abs(x1) + abs(x2)\n",
    "        h2 = h + abs(y1) + abs(y2)\n",
    "        data = (\n",
    "            x1, y1,\n",
    "            -x1, h2 - y2,\n",
    "            w2 + x2, h2 + y2,\n",
    "            w2 - x2, -y1,\n",
    "        )\n",
    "        im = im.resize((w2, h2))\n",
    "        # im = im.transform((w, h), QUAD, data)\n",
    "        return im\n",
    "\n",
    "    def create_captcha_image(\n",
    "            self,\n",
    "            chars: str,\n",
    "            color: ColorTuple,\n",
    "            background: ColorTuple) -> Image:\n",
    "        \"\"\"Create the CAPTCHA image itself.\n",
    "\n",
    "        :param chars: text to be generated.\n",
    "        :param color: color of the text.\n",
    "        :param background: color of the background.\n",
    "\n",
    "        The color should be a tuple of 3 numbers, such as (0, 255, 255).\n",
    "        \"\"\"\n",
    "        image = createImage('RGB', (self._width, self._height), background)\n",
    "        # image = createImage('RGB', (self._width, self._height))\n",
    "        draw = Draw(image)\n",
    "\n",
    "        images: t.List[Image] = []\n",
    "        for c in chars:\n",
    "            # if random.random() > 0.5:\n",
    "            #     images.append(self._draw_character(\" \", draw, color))\n",
    "            images.append(self._draw_character(c, draw, color))\n",
    "\n",
    "        text_width = sum([im.size[0] for im in images])\n",
    "\n",
    "        width = max(text_width, self._width)\n",
    "        image = image.resize((width, self._height))\n",
    "\n",
    "        average = int(text_width / len(chars))\n",
    "#         rand = int(0.25 * average)\n",
    "        offset = int(average * 0.1)\n",
    "\n",
    "        for im in images:\n",
    "            w, h = im.size\n",
    "            mask = im.convert('L').point(self.lookup_table)\n",
    "            image.paste(im, (offset, int((self._height - h) / 2)), mask)\n",
    "            # offset = offset + w + random.randint(-rand, 0)\n",
    "            offset = offset + w # + random.randint(-int(0.005 * average), 0)\n",
    "\n",
    "        if width > self._width:\n",
    "            image = image.resize((self._width, self._height))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def generate_image(self, chars: str) -> Image:\n",
    "        \"\"\"Generate the image of the given characters.\n",
    "\n",
    "        :param chars: text to be generated.\n",
    "        \"\"\"\n",
    "        # background = random_color(238, 255)\n",
    "        # color = random_color(10, 200, random.randint(220, 255))\n",
    "        background = random_color(255, 255)\n",
    "        color = (255, 0, 0)\n",
    "        im = self.create_captcha_image(chars, color, background)\n",
    "        # self.create_noise_dots(im, color)\n",
    "        # self.create_noise_curve(im, color)\n",
    "        im = im.filter(SMOOTH)\n",
    "        return im\n",
    "\n",
    "    def generate(self, chars: str, format: str = 'png') -> BytesIO:\n",
    "        \"\"\"Generate an Image Captcha of the given characters.\n",
    "\n",
    "        :param chars: text to be generated.\n",
    "        :param format: image file format\n",
    "        \"\"\"\n",
    "        im = self.generate_image(chars)\n",
    "        out = BytesIO()\n",
    "        im.save(out, format=format)\n",
    "        out.seek(0)\n",
    "        return out\n",
    "\n",
    "    def write(self, chars: str, output: str, format: str = 'png') -> None:\n",
    "        \"\"\"Generate and write an image CAPTCHA data to the output.\n",
    "\n",
    "        :param chars: text to be generated.\n",
    "        :param output: output destination.\n",
    "        :param format: image file format\n",
    "        \"\"\"\n",
    "        im = self.generate_image(chars)\n",
    "        im.save(output, format=format)\n",
    "\n",
    "\n",
    "def random_color(\n",
    "        start: int,\n",
    "        end: int,\n",
    "        opacity: t.Optional[int] = None) -> ColorTuple:\n",
    "    red = random.randint(start, end)\n",
    "    green = random.randint(start, end)\n",
    "    blue = random.randint(start, end)\n",
    "    if opacity is None:\n",
    "        return (red, green, blue)\n",
    "    return (red, green, blue, opacity)\n",
    "\n",
    "# https://github.com/lepture/captcha/blob/master/src/captcha/image.py\n",
    "# from captcha.image import ImageCaptcha\n",
    "\n",
    "# image = ImageCaptcha(height=50, width=130, font_sizes=[40])\n",
    "\n",
    "# for i in range(10):\n",
    "#     data = image.generate(str(i))\n",
    "#     image.write(str(i), DATA_TRAIN_DIR + str(i) + '.jpg')\n",
    "\n",
    "import itertools, random, uuid\n",
    "\n",
    "def _gen_captcha(img_dir, num_per_image, n, width, height, choices, max_images_count):\n",
    "\n",
    "    image = ImageCaptcha(width=width, height=height, font_sizes=[25])\n",
    "\n",
    "    remain_count = max_images_count\n",
    "    epoche_count = len(list(itertools.permutations(choices, num_per_image)))\n",
    "\n",
    "    # print('generating %s epoches of captchas in %s.' % (n, img_dir))\n",
    "\n",
    "    for _ in range(n):\n",
    "        samples = itertools.permutations(choices, num_per_image)\n",
    "        samples = random.sample(list(samples), remain_count)\n",
    "        if remain_count > 0 and remain_count < epoche_count:\n",
    "            # print('only %s records used in epoche %s. epoche_count: %s' % (remain_count, _+1, epoche_count))\n",
    "            samples = random.sample(list(samples), remain_count)\n",
    "        \n",
    "        for i in samples:\n",
    "            captcha = ''.join(i)\n",
    "            fn = os.path.join(img_dir, '%s_%s.jpg' % (captcha, uuid.uuid4()))\n",
    "            # fn = os.path.join(img_dir, '%s.jpg' % (captcha))\n",
    "            image.write(captcha, fn)\n",
    "            \n",
    "        if n < 20:\n",
    "            print('(%s/%s) epoches finished' % (_+1, n))\n",
    "            \n",
    "\n",
    "SELECTED_CHARS = '2345678abcdefghkmnprwxy'\n",
    "_gen_captcha(GEN_CAPTCHA_DIR_ONE, 1, 10000, 50, 50, SELECTED_CHARS, 1)\n",
    "\n",
    "# SELECTED_CHARS = '2345678abcdefghkmnprwxy'\n",
    "_gen_captcha(GEN_CAPTCHA_DIR_FIVE, 5, 10000, 130, 50, SELECTED_CHARS, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140e603f-7c57-460a-bd90-6ee25c9498ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa8600-fa1f-42c6-90dd-9cf7101edf4d",
   "metadata": {},
   "source": [
    "### Separated characters from catcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf33601-0c75-4609-ae4b-3e858f7eec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'k',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "def convert_png_jpg_dir(dir_png, dir_jpg):\n",
    "    def convert_png_jpg_(png_path, jpg_path):\n",
    "        try:\n",
    "            png_image = Image.open(png_path)\n",
    "            jpg_image = Image.new(\"RGB\", png_image.size, (255, 255, 255))  # Creating a white background\n",
    "            jpg_image.paste(png_image, (0, 0), png_image)\n",
    "            jpg_image.save(jpg_path, \"JPEG\", quality=100)\n",
    "            print(f\"Conversion successful: {png_path} -> {jpg_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during conversion: {e}\")\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    file_list = os.listdir(dir_png)\n",
    "    file_chars = {}\n",
    "\n",
    "    # Iterate over the files and print their names\n",
    "    for file_name in file_list:\n",
    "        if os.path.isfile(os.path.join(dir_png, file_name)):\n",
    "            file_png = os.path.join(dir_png, file_name)\n",
    "            file_jpg = os.path.join(dir_jpg, file_name.replace(\".png\", \".jpg\"))\n",
    "            chars_ls = list(file_name.replace(\".png\", \"\"))\n",
    "            for pos, c in enumerate(chars_ls):\n",
    "                file_chars[c] = (file_chars[c] + [(file_jpg, pos)]) if c in file_chars else [(file_jpg, pos)]\n",
    "            # convert_png_jpg_(file_png, file_jpg)\n",
    "            \n",
    "    return file_chars\n",
    "        \n",
    "MST_DIR_PNG = './save_temp/captcha_test/captcha_mst/png/'  # Replace with the path to your directory\n",
    "MST_DIR_JPG = './save_temp/captcha_test/captcha_mst/jpg/'\n",
    "\n",
    "file_chars = convert_png_jpg_dir(MST_DIR_PNG, MST_DIR_JPG)\n",
    "\n",
    "# sorted\n",
    "file_chars = dict(sorted(file_chars.items()))\n",
    "file_chars = {c: sorted(file_chars[c], key=lambda x: x[1])  for c in file_chars}\n",
    "list(file_chars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3f309-b55a-433e-b6db-ea79f7dfc6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf8d023-ffb1-42bb-970c-14888bbc0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(fimg):\n",
    "    def convert_jpg_(fimg):\n",
    "\n",
    "        png_image = Image.open(fimg) if type(fimg) is str else fimg\n",
    "\n",
    "        jpg_image = Image.new(\"RGB\", png_image.size, (255, 255, 255))  # Creating a white background\n",
    "        jpg_image.paste(png_image, (0, 0), png_image)\n",
    "        jpeg_array = np.array(jpg_image)\n",
    "\n",
    "        return jpeg_array\n",
    "\n",
    "    image = cv2.imread(fimg, cv2.IMREAD_UNCHANGED) if type(fimg) is str and '.jpg' in fimg else \\\n",
    "                    convert_jpg_(fimg)\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated_img = cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "    return dilated_img\n",
    "    \n",
    "# def remove_noise(fimg):\n",
    "#     def convert_jpg_(fimg):\n",
    "        \n",
    "#         png_image = Image.open(fimg)\n",
    "        \n",
    "#         jpg_image = Image.new(\"RGB\", png_image.size, (255, 255, 255))  # Creating a white background\n",
    "#         jpg_image.paste(png_image, (0, 0), png_image)\n",
    "#         jpeg_array = np.array(jpg_image)\n",
    "\n",
    "#         return jpeg_array\n",
    "\n",
    "#     image = convert_jpg_(fimg) if '.png' in fimg else \\\n",
    "#                     cv2.imread(fimg, cv2.IMREAD_UNCHANGED)\n",
    "#     kernel = np.ones((2, 2), np.uint8)\n",
    "#     dilated_img = cv2.dilate(image, kernel, iterations=1)\n",
    "    \n",
    "#     return dilated_img\n",
    "    \n",
    "def chop_multi_versions(img, num_chars, chop_wd = [0, -2, -4, 2, 4], chop_width=[0]):\n",
    "    def find_first_position_(img):\n",
    "        arr_pos = []\n",
    "\n",
    "        for r in range(0, img.shape[0]):\n",
    "            fwhite = None\n",
    "            for c in range(0, img.shape[1]):\n",
    "                s = sum(img[r][c])\n",
    "                fwhite = c if s == 765 else fwhite            \n",
    "                if fwhite is not None and (s != 765):  \n",
    "                    arr_pos.append(c) if c < img.shape[1] - 3 else None\n",
    "                    break\n",
    "        return min(arr_pos)\n",
    "\n",
    "    def find_last_position_(img):\n",
    "        arr_pos = []\n",
    "\n",
    "        for r in range(0, img.shape[0]):\n",
    "            fwhite = None\n",
    "            for c in range(0, img.shape[1]):\n",
    "                c = img.shape[1] - c - 1\n",
    "                s = sum(img[r][c])            \n",
    "                fwhite = c if s == 765 else fwhite\n",
    "                if fwhite is not None and (s != 765):\n",
    "                    arr_pos.append(c) if c > 5 else None\n",
    "                    break\n",
    "\n",
    "        return max(arr_pos)\n",
    "\n",
    "    def chop_first_last_(img, first_chop, last_chop):\n",
    "        return np.array([img[i][first_chop:last_chop] for i in range(0, img.shape[0])])\n",
    "\n",
    "    def chop_equal_(img, num_chars):\n",
    "        equal_size = int(img.shape[1]/num_chars)\n",
    "        return [img[0:img.shape[0], i:i+equal_size,:] for i in range(0, equal_size*num_chars, equal_size)]\n",
    "\n",
    "\n",
    "    def chop_multi_(img, num_chars, chop_wd = [0, -2, -4, 2, 4], chop_width=[0]):\n",
    "        equal_size = int(img.shape[1]/num_chars)\n",
    "        chop_multi = [[] for i in range(0, num_chars)]\n",
    "        chop_size = [(x, x, w) for x in chop_wd for w in chop_width]        \n",
    "        for i in range(0, num_chars):\n",
    "            for s in chop_size:\n",
    "                ri = i*equal_size\n",
    "                start, end = max(0, ri + s[0]), min(img.shape[1], ri + equal_size + s[1] + s[2])\n",
    "                \n",
    "                t_img = img[0:img.shape[0], start:end,:]\n",
    "                \n",
    "                # padding if width less than equal width\n",
    "                num_padded = (equal_size + max(chop_width)) - (end - start)\n",
    "                num_left = int(num_padded / 2)\n",
    "                num_right = num_padded - num_left\n",
    "                \n",
    "                padded_left = np.full((num_left, 3), 255) if num_padded > 0 else None\n",
    "                padded_right = np.full((num_right, 3), 255) if num_padded > 0 else None\n",
    "                t_img = np.array([np.concatenate((padded_left, t, padded_right), axis=0) \n",
    "                                          for t in t_img]) if num_padded > 0 else t_img\n",
    "\n",
    "                chop_multi[i].append(t_img)\n",
    "\n",
    "        return chop_multi\n",
    "    \n",
    "    def padding_multi_(chop_multi, padded = np.full((2, 3), 255)):\n",
    "        padded_multi = [[] for i in range(len(chop_multi))]\n",
    "        for i in range(len(chop_multi)):\n",
    "            for j in range(len(chop_multi[i])):\n",
    "                img = chop_multi[i][j]\n",
    "                t_img = np.array([np.concatenate((padded, t, padded), axis=0) for t in img])\n",
    "                padded_multi[i].append(t_img.astype(np.uint8))\n",
    "                \n",
    "        return padded_multi\n",
    "\n",
    "        \n",
    "    first_chop = find_first_position_(img)\n",
    "    last_chop = find_last_position_(img)\n",
    "    chop_image = chop_first_last_(img, first_chop, last_chop)    \n",
    "    chop_list = chop_multi_(chop_image, num_chars, chop_wd, chop_width)    \n",
    "    padding_list = padding_multi_(chop_list)\n",
    "    \n",
    "    return padding_list\n",
    "\n",
    "def extract_contours_all(img_list):\n",
    "    def extract_contours_(img):\n",
    "        img = imutils.resize(img, width=32, height=32)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edged = cv2.Canny(blurred, img.shape[0], img.shape[1])\n",
    "        # edged = cv2.Canny(img, img.shape[0], img.shape[1])\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # cnts_sorted = sorted(cnts, key=lambda c: cv2.boundingRect(c)[0])\n",
    "        cnts_sorted = cnts\n",
    "\n",
    "        chars = []\n",
    "        for i, c in enumerate(cnts_sorted):\n",
    "\n",
    "            # compute the bounding box of the contour\n",
    "            (x, y, w, h) = cv2.boundingRect(c)            \n",
    "\n",
    "            if w >= 10 and h >= 10:\n",
    "                roi = edged[y:y + h, x:x + w]\n",
    "                thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "                (tH, tW) = thresh.shape\n",
    "\n",
    "                # if the width is greater than the height, resize along the width dimension\n",
    "                rsw, rsh = 32, 32                \n",
    "                thresh = imutils.resize(thresh, width=rsw) if tW > tH else \\\n",
    "                                imutils.resize(thresh, height=rsh)\n",
    "                (tH, tW) = thresh.shape\n",
    "                dX = int(max(0, rsw - tW) / 2.0)\n",
    "                dY = int(max(0, rsh - tH) / 2.0)\n",
    "\n",
    "                # pad the image and force 32x32 dimensions\n",
    "                padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY, left=dX, right=dX, \n",
    "                                            borderType=cv2.BORDER_CONSTANT,value=(0, 0, 0))\n",
    "                padded = cv2.resize(padded, (rsw, rsh))\n",
    "                padded = padded.astype(\"float32\")\n",
    "                padded = np.expand_dims(padded, axis=-1)\n",
    "                chars.append((padded, (x, y, w, h)))\n",
    "\n",
    "        chars = sorted(chars, key=lambda c: c[1][2], reverse=True)\n",
    "        return chars\n",
    "    \n",
    "    \n",
    "    def extract_contours_list_(img_list):\n",
    "        chars_list = None\n",
    "        for img in img_list:\n",
    "            cts = extract_contours_(img)\n",
    "            if len(cts) > 0:\n",
    "                chars_list = [cts[0]] if chars_list is None else chars_list + [cts[0]]\n",
    "        # chars_list = sorted(chars_list, key=lambda c: c[1][2], reverse=True)\n",
    "        \n",
    "        return chars_list\n",
    "\n",
    "        \n",
    "    return extract_contours_list_(img_list)\n",
    "\n",
    "def process_char(img, pos, num_chars=5, chop_wd = [0, -2, -4, 2, 4], chop_width=[0]):\n",
    "    img_rn = remove_noise(img)\n",
    "    chop_imgs = chop_multi_versions(img_rn, num_chars, chop_wd, chop_width)\n",
    "    all_chars = extract_contours_all(chop_imgs[pos])\n",
    "\n",
    "    return all_chars\n",
    "\n",
    "def display_multi_2d(img_list, ncols=5, idepth=None):\n",
    "    \n",
    "    nrows = sum([math.ceil(len(x) / ncols) for x in img_list])\n",
    "\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "    \n",
    "    iprev = 0\n",
    "    for i in range(len(img_list)):\n",
    "        for j in range(len(img_list[i])):\n",
    "            irow = iprev + math.floor(j / ncols)\n",
    "            icol = j - math.floor(j / ncols) * ncols\n",
    "            img = img_list[i][j] if idepth is None else img_list[i][j][idepth]\n",
    "            axes[icol].imshow(img) if nrows == 1 else axes[irow, icol].imshow(img)\n",
    "        iprev = irow + 1\n",
    "    \n",
    "def display_multi(img_list, ncols=5, idepth=None):\n",
    "    \n",
    "    nrows = math.ceil(len(img_list) / ncols)\n",
    "\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(nrows, ncols if nrows > 1 else len(img_list))\n",
    "    for i in range(len(img_list)):\n",
    "        irow, icol = math.floor(i/ncols), i%ncols\n",
    "        img = img_list[i] if idepth is None else img_list[i][idepth]\n",
    "        axes.imshow(img) if len(img_list) == 1 else None\n",
    "        axes[icol].imshow(img) if nrows == 1 else axes[irow, icol].imshow(img)\n",
    "\n",
    "        \n",
    "# G_NUM_CHARS, G_CHOP_WD, G_CHOP_SIZE = 5, [0, -2, -4, 2, 4], [2, 4]\n",
    "\n",
    "# all_chars = []\n",
    "# for c in list(file_chars.items()):\n",
    "#     fimg = c[1][0][0]\n",
    "#     pos = c[1][0][1]\n",
    "#     chars_img = process_char(fimg, pos, G_NUM_CHARS, G_CHOP_WD, G_CHOP_SIZE)\n",
    "#     all_chars.append(chars_img)\n",
    "\n",
    "# display_multi_2d(all_chars, 5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190b0c0-b35d-4c7b-a2dc-75c87927bc18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6358adb-f1f6-413d-ac71-d99b970d6c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4b28a-a6ee-4914-a899-17c5cdee48a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8d0dd-3ba7-401f-a96b-3991ba50852e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638e6a12-8f9b-4924-838b-8e2fff3faa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./save_temp/captcha_test/captcha_mst/jpg/',\n",
       " './save_temp/captcha_test/train_mst/')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MST_DIR_TRAIN = './save_temp/captcha_test/train_mst/'\n",
    "MST_DIR_JPG, MST_DIR_TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6dbe07-2642-4dac-9028-24f13b35d9cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Gen training data from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ada3e7-8f94-40fd-b233-ce7616588855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb79e39b-f97d-416a-92d6-10745cac7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_data(DIR_JPG, DIR_GEN, num_chars=5, chop_wd=[0, -2, -4, 2, 4], chop_width=[0, 2, 4]):\n",
    "    files_process = glob.glob(os.path.join(os.path.join(DIR_JPG), \"*.jpg\"))\n",
    "    for fimg in files_process:\n",
    "        chars_ls = fimg.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "        for pos, c in enumerate(chars_ls):\n",
    "            chars_img = process_char(fimg, pos, num_chars, chop_wd, chop_width)\n",
    "            for cimg in chars_img:\n",
    "                fnpy = f\"{DIR_GEN}{c}_{datetime.now().strftime('%y%m%d%H%M%S%S%f')}.npy\"\n",
    "                ximg = np.array([np.repeat(x, 3, axis=1) for x in cimg[0]], np.uint8)\n",
    "                np.save(fnpy, ximg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d5bf9e-b440-48b2-9807-88f903a3b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# chars_img_all = {}\n",
    "# files_process = glob.glob(os.path.join(os.path.join(MST_DIR_JPG), \"*.jpg\"))\n",
    "# for fimg in files_process:\n",
    "#     chars_ls = fimg.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "#     for pos, c in enumerate(chars_ls):\n",
    "#         chars_img = process_char(fimg, pos, num_chars=5, chop_wd=[0, -2, -4, 2, 4], chop_width=[0, 2, 4])\n",
    "#         for cimg in chars_img:            \n",
    "#             f = f\"{MST_DIR_TRAIN}{c}_{datetime.now().strftime('%y%m%d%H%M%S%S%f')}.jpg\"\n",
    "#             cv2.imwrite(f, cimg[0])\n",
    "\n",
    "gen_train_data(MST_DIR_JPG, MST_DIR_TRAIN, 5, [0, -2, -4, 2, 4], [0, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074735aa-bc89-4bb9-97f5-a8d014557c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./save_temp/captcha_test/gen_captcha/one_char/',\n",
       " './save_temp/captcha_test/train_gen/one_char/',\n",
       " './save_temp/captcha_test/gen_captcha/five_chars/',\n",
       " './save_temp/captcha_test/train_gen/five_chars/')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEN_DIR_TRAIN_ONE = './save_temp/captcha_test/train_gen/one_char/'\n",
    "GEN_DIR_TRAIN_FIVE = './save_temp/captcha_test/train_gen/five_chars/'\n",
    "GEN_CAPTCHA_DIR_ONE, GEN_DIR_TRAIN_ONE, \\\n",
    "GEN_CAPTCHA_DIR_FIVE, GEN_DIR_TRAIN_FIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fe197-ebb8-48c1-a34d-58853d22dc60",
   "metadata": {},
   "source": [
    "#### Gen training data from captcha - five chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "863548bb-46b6-4e6a-a502-a96a07b54a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars_img_all = {}\n",
    "# files_process = glob.glob(os.path.join(os.path.join(GEN_CAPTCHA_DIR_FIVE), \"*.jpg\"))\n",
    "# for fimg in files_process:\n",
    "#     chars_ls = fimg.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "#     for pos, c in enumerate(chars_ls):\n",
    "#         chars_img = process_char(fimg, pos, num_chars=5, chop_wd=[0, -2, 2], chop_width=[0, 2])\n",
    "#         for cimg in chars_img:\n",
    "#             f = f\"{GEN_DIR_TRAIN_FIVE}{c}_{datetime.now().strftime('%y%m%d%H%M%S%S%f')}.jpg\"\n",
    "#             cv2.imwrite(f, cimg[0])\n",
    "\n",
    "gen_train_data(GEN_CAPTCHA_DIR_FIVE, GEN_DIR_TRAIN_FIVE, 5, [0, -2, 2], [0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd46121-57d1-4a9e-87f8-ec6a4ce9a93b",
   "metadata": {},
   "source": [
    "#### Gen training data from captcha - one char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a3d392-1360-48b0-829a-995b1155b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars_img_all = {}\n",
    "# files_process = glob.glob(os.path.join(os.path.join(GEN_CAPTCHA_DIR_ONE), \"*.jpg\"))\n",
    "# for fimg in files_process:\n",
    "#     chars_ls = fimg.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "#     for pos, c in enumerate(chars_ls):\n",
    "#         chars_img = process_char(fimg, pos, num_chars=1, chop_wd=[0], chop_width=[0])\n",
    "#         for cimg in chars_img:\n",
    "#             f = f\"{GEN_DIR_TRAIN_ONE}{c}_{datetime.now().strftime('%y%m%d%H%M%S%S%f')}.jpg\"\n",
    "#             cv2.imwrite(f, cimg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c6ba4d-f0e6-491c-9c12-9e492dc81500",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_data(GEN_CAPTCHA_DIR_ONE, GEN_DIR_TRAIN_ONE, 1, [0], [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44089d20-9446-4bf3-94ed-b4143baa6dad",
   "metadata": {},
   "source": [
    "#### Gen training data from MST extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6467ad9-1250-40ea-8f1b-1ba6ed949023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/truong.vu.1/opt/anaconda3/envs/general/lib/python3.8/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "FILE_COMMON_PATH = './'\n",
    "f = FILE_COMMON_PATH + \"lib_common.ipynb\"\n",
    "%run $f\n",
    "\n",
    "f = FILE_COMMON_PATH + \"lib_db.ipynb\"\n",
    "%run $f\n",
    "\n",
    "f = FILE_COMMON_PATH + \"config.ipynb\"\n",
    "%run $f\n",
    "\n",
    "f = FILE_COMMON_PATH + \"lib_crawl.ipynb\"\n",
    "%run $f\n",
    "\n",
    "f = FILE_COMMON_PATH + \"lib_ftp.ipynb\"\n",
    "%run $f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c6b248-64eb-4b13-a60c-d6cd0abe9e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>pred</th>\n",
       "      <th>result</th>\n",
       "      <th>etl_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230908094515970352                            ...</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAAAIIAAAAyCAYAAACQyQOIAA...</td>\n",
       "      <td>62ch2                                         ...</td>\n",
       "      <td>PASSED                                        ...</td>\n",
       "      <td>2023-09-08 16:45:15.967943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230908094515970356                            ...</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAAAIIAAAAyCAYAAACQyQOIAA...</td>\n",
       "      <td>dcnmd                                         ...</td>\n",
       "      <td>PASSED                                        ...</td>\n",
       "      <td>2023-09-08 16:45:15.967943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  230908094515970352                            ...   \n",
       "1  230908094515970356                            ...   \n",
       "\n",
       "                                                 img  \\\n",
       "0  iVBORw0KGgoAAAANSUhEUgAAAIIAAAAyCAYAAACQyQOIAA...   \n",
       "1  iVBORw0KGgoAAAANSUhEUgAAAIIAAAAyCAYAAACQyQOIAA...   \n",
       "\n",
       "                                                pred  \\\n",
       "0  62ch2                                         ...   \n",
       "1  dcnmd                                         ...   \n",
       "\n",
       "                                              result  \\\n",
       "0  PASSED                                        ...   \n",
       "1  PASSED                                        ...   \n",
       "\n",
       "                    etl_date  \n",
       "0 2023-09-08 16:45:15.967943  \n",
       "1 2023-09-08 16:45:15.967943  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# METABASE_SSH = {\n",
    "#     'ssh_pkey': ssh_pkey,\n",
    "#     'ssh_server': ssh_server,\n",
    "# }\n",
    "\n",
    "# METABASE_DB = {\n",
    "#     'drivername': 'postgresql',\n",
    "#     'host': '10.7.14.166',\n",
    "#     'port': 5432,\n",
    "#     'database': 'metabase',\n",
    "#     'username': 'metabase',\n",
    "#     'password': 'EqbW87tSBk56Em2F'\n",
    "# }\n",
    "\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM dbi.tax_captcha\n",
    "where result = 'PASSED'\n",
    "\"\"\"\n",
    "\n",
    "df_mst_extra = read_sql_ssh(METABASE_SSH, METABASE_DB, query, other_params={})\n",
    "df_mst_extra.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6edc13f-9b78-4923-8ec5-a4ce1b76c7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3838"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_mst_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "452a87a5-1f86-4b1b-8148-4426aab7e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "MST_DIR_TRAIN_EXTRA = './save_temp/captcha_test/train_mst_extra/'\n",
    "\n",
    "def gen_train_data(df_mst_extra, DIR_GEN, num_chars=5, chop_wd=[0, -2, -4, 2, 4], chop_width=[0, 2, 4]):\n",
    "    \n",
    "    def execute_item_(img, chars_ls):\n",
    "        for pos, c in enumerate(chars_ls):\n",
    "            imgdata = base64.b64decode(str(img))\n",
    "            img_captcha = Image.open(io.BytesIO(imgdata))                \n",
    "            chars_img = process_char(img_captcha, pos, num_chars, chop_wd, chop_width)\n",
    "            for cimg in chars_img:\n",
    "                fnpy = f\"{DIR_GEN}{c}_{datetime.now().strftime('%y%m%d%H%M%S%S%f')}.npy\"\n",
    "                ximg = np.array([np.repeat(x, 3, axis=1) for x in cimg[0]], np.uint8)\n",
    "                np.save(fnpy, ximg)\n",
    "                \n",
    "    df_mst_extra.apply(lambda x: execute_item_(x['img'], x['pred'].strip()), axis=1)\n",
    "    \n",
    "gen_train_data(df_mst_extra, MST_DIR_TRAIN_EXTRA, 5, [0, -2, -4, 2, 4], [0, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e82ec-0ff4-4dd4-af7c-3bae8412653a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7038334a-b70b-440e-91de-ad565e7b382b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "817398f3-7740-4ff0-8bf4-9a81be5abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = './save_temp/captcha_test/model_checkpoint/'\n",
    "H, W, C = 32, 32, 3\n",
    "D, N_LABELS = 1, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcd0d6d0-78fa-4f69-b2cb-5a57cb5c9287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              263168    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 256)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 581,888\n",
      "Trainable params: 581,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 09:10:39.019875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(H, W, C))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(D * N_LABELS, activation='softmax')(x)\n",
    "x = layers.Reshape((D, N_LABELS))(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fc15725-7a37-4dc5-bbb7-869bc6e69abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    images, labels = [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, label = r['file'], r['label']\n",
    "            # im = Image.open(file)\n",
    "            # im = im.resize((H, W))            \n",
    "            # im = cv2.imread(file)            \n",
    "            im = np.load(file)\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(np.array(im))\n",
    "            labels.append(np.array([np.array(to_categorical(ord(i), N_LABELS)) for i in label]))\n",
    "            if len(images) >= batch_size:\n",
    "#                 print(np.array(images), np.array(labels))\n",
    "                yield np.array(images), np.array(labels)\n",
    "                images, labels = [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d467e34-b433-4d77-9d29-6aa99a383f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39c716f7-8ca0-4868-beb7-daf857f5b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filepath(filepath):\n",
    "    try:\n",
    "        path, filename = os.path.split(filepath)\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "        label, _ = filename.split(\"_\")\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print('error to parse %s. %s' % (filepath, e))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1822d16d-0eb9-493a-be0d-a60b14ccb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = GEN_DIR_TRAIN_ONE\n",
    "\n",
    "# # create a pandas data frame of images, age, gender and race\n",
    "# files = glob.glob(os.path.join(DATA_DIR, \"*.jpg\"))\n",
    "# attributes = list(map(parse_filepath, files))\n",
    "\n",
    "# df = pd.DataFrame(attributes)\n",
    "# df['file'] = files\n",
    "# df.columns = ['label', 'file']\n",
    "# df = df.dropna()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c79f52b9-15cc-4592-84e8-8167109eec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = np.random.permutation(len(df))\n",
    "# train_up_to = int(len(df) * 0.7)\n",
    "# train_idx = p[:train_up_to]\n",
    "# test_idx = p[train_up_to:]\n",
    "\n",
    "# # split train_idx further into training and validation set\n",
    "# train_up_to = int(train_up_to * 0.7)\n",
    "# train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "# print('train count: %s, valid count: %s, test count: %s' % (\n",
    "#     len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f867a2f-1daa-4883-a5a2-90b29c3cd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# batch_size = 64\n",
    "# valid_batch_size = 64\n",
    "# train_gen = get_data_generator(df, train_idx, for_training=True, batch_size=batch_size)\n",
    "# valid_gen = get_data_generator(df, valid_idx, for_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss')\n",
    "# ]\n",
    "\n",
    "# history = model.fit(train_gen,\n",
    "#                     steps_per_epoch=len(train_idx)//batch_size,\n",
    "#                     epochs=5,\n",
    "# #                     callbacks=callbacks,\n",
    "#                     validation_data=valid_gen,\n",
    "#                     validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71dd69d9-0d30-433e-bff3-222131616e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- train count: 25452, valid count: 10908, test count: 15584\n",
      "Epoch 1/5\n",
      "397/397 [==============================] - 16s 39ms/step - loss: 1.0320 - accuracy: 0.7068 - val_loss: 0.0425 - val_accuracy: 0.9881\n",
      "Epoch 2/5\n",
      "397/397 [==============================] - 14s 36ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "397/397 [==============================] - 14s 36ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "397/397 [==============================] - 14s 36ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "397/397 [==============================] - 13s 34ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "------- train count: 34125, valid count: 14626, test count: 20894\n",
      "Epoch 1/5\n",
      "533/533 [==============================] - 21s 39ms/step - loss: 0.5134 - accuracy: 0.8726 - val_loss: 0.3719 - val_accuracy: 0.9036\n",
      "Epoch 2/5\n",
      "533/533 [==============================] - 19s 36ms/step - loss: 0.2646 - accuracy: 0.9291 - val_loss: 0.3234 - val_accuracy: 0.9177\n",
      "Epoch 3/5\n",
      "533/533 [==============================] - 19s 36ms/step - loss: 0.1878 - accuracy: 0.9483 - val_loss: 0.3238 - val_accuracy: 0.9195\n",
      "Epoch 4/5\n",
      "533/533 [==============================] - 19s 36ms/step - loss: 0.1393 - accuracy: 0.9607 - val_loss: 0.3134 - val_accuracy: 0.9298\n",
      "Epoch 5/5\n",
      "533/533 [==============================] - 19s 36ms/step - loss: 0.1021 - accuracy: 0.9710 - val_loss: 0.3374 - val_accuracy: 0.9280\n",
      "------- train count: 7325, valid count: 3140, test count: 4485\n",
      "Epoch 1/5\n",
      "114/114 [==============================] - 5s 42ms/step - loss: 0.9358 - accuracy: 0.7760 - val_loss: 0.6498 - val_accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "114/114 [==============================] - 4s 32ms/step - loss: 0.3556 - accuracy: 0.9062 - val_loss: 0.5208 - val_accuracy: 0.8734\n",
      "Epoch 3/5\n",
      "114/114 [==============================] - 4s 32ms/step - loss: 0.1700 - accuracy: 0.9571 - val_loss: 0.4696 - val_accuracy: 0.8938\n",
      "Epoch 4/5\n",
      "114/114 [==============================] - 4s 31ms/step - loss: 0.0838 - accuracy: 0.9826 - val_loss: 0.4884 - val_accuracy: 0.9011\n",
      "Epoch 5/5\n",
      "114/114 [==============================] - 4s 32ms/step - loss: 0.0552 - accuracy: 0.9894 - val_loss: 0.5336 - val_accuracy: 0.8992\n",
      "------- train count: 140842, valid count: 60361, test count: 86231\n",
      "Epoch 1/5\n",
      "2200/2200 [==============================] - 85s 39ms/step - loss: 0.3120 - accuracy: 0.9153 - val_loss: 0.2303 - val_accuracy: 0.9346\n",
      "Epoch 2/5\n",
      "2200/2200 [==============================] - 78s 35ms/step - loss: 0.1823 - accuracy: 0.9475 - val_loss: 0.2042 - val_accuracy: 0.9418\n",
      "Epoch 3/5\n",
      "2200/2200 [==============================] - 76s 35ms/step - loss: 0.1332 - accuracy: 0.9599 - val_loss: 0.2150 - val_accuracy: 0.9422\n",
      "Epoch 4/5\n",
      "2200/2200 [==============================] - 78s 35ms/step - loss: 0.1041 - accuracy: 0.9680 - val_loss: 0.2245 - val_accuracy: 0.9452\n",
      "Epoch 5/5\n",
      "2200/2200 [==============================] - 78s 36ms/step - loss: 0.0878 - accuracy: 0.9723 - val_loss: 0.2292 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "DATA_DIR = [GEN_DIR_TRAIN_ONE, GEN_DIR_TRAIN_FIVE, MST_DIR_TRAIN, MST_DIR_TRAIN_EXTRA]\n",
    "\n",
    "for dd in DATA_DIR:\n",
    "    # create a pandas data frame of images, age, gender and race\n",
    "    # files = glob.glob(os.path.join(dd, \"*.jpg\"))\n",
    "    files = glob.glob(os.path.join(dd, \"*.npy\"))\n",
    "    attributes = list(map(parse_filepath, files))\n",
    "\n",
    "    df = pd.DataFrame(attributes)\n",
    "    df['file'] = files\n",
    "    df.columns = ['label', 'file']\n",
    "    df = df.dropna()\n",
    "    \n",
    "    p = np.random.permutation(len(df))\n",
    "    train_up_to = int(len(df) * 0.7)\n",
    "    train_idx = p[:train_up_to]\n",
    "    test_idx = p[train_up_to:]\n",
    "\n",
    "    # split train_idx further into training and validation set\n",
    "    train_up_to = int(train_up_to * 0.7)\n",
    "    train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "    print('------- train count: %s, valid count: %s, test count: %s' % (\n",
    "        len(train_idx), len(valid_idx), len(test_idx)))\n",
    "\n",
    "    batch_size = 64\n",
    "    valid_batch_size = 64\n",
    "    train_gen = get_data_generator(df, train_idx, for_training=True, batch_size=batch_size)\n",
    "    valid_gen = get_data_generator(df, valid_idx, for_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss')\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        steps_per_epoch=len(train_idx)//batch_size,\n",
    "                        epochs=5,\n",
    "    #                     callbacks=callbacks,\n",
    "                        validation_data=valid_gen,\n",
    "                        validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c768994-92b1-4f8d-8ec9-ecf4885f3ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train_history(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].plot(history.history['accuracy'], label='Train accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].legend() \n",
    "\n",
    "    axes[1].plot(history.history['loss'], label='Training loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].legend()\n",
    "\n",
    "plot_train_history(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55144e3d-54f5-4895-9672-114d90f29e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84469</th>\n",
       "      <td>8</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/8_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>e</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/e_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>w</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/w_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>w</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/w_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123802</th>\n",
       "      <td>n</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/n_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260269</th>\n",
       "      <td>5</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/5_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21957</th>\n",
       "      <td>b</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/b_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47703</th>\n",
       "      <td>d</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/d_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62273</th>\n",
       "      <td>w</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/w_230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171848</th>\n",
       "      <td>8</td>\n",
       "      <td>./save_temp/captcha_test/train_mst_extra/8_230...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               file\n",
       "84469      8  ./save_temp/captcha_test/train_mst_extra/8_230...\n",
       "3124       e  ./save_temp/captcha_test/train_mst_extra/e_230...\n",
       "20469      w  ./save_temp/captcha_test/train_mst_extra/w_230...\n",
       "7859       w  ./save_temp/captcha_test/train_mst_extra/w_230...\n",
       "123802     n  ./save_temp/captcha_test/train_mst_extra/n_230...\n",
       "...      ...                                                ...\n",
       "260269     5  ./save_temp/captcha_test/train_mst_extra/5_230...\n",
       "21957      b  ./save_temp/captcha_test/train_mst_extra/b_230...\n",
       "47703      d  ./save_temp/captcha_test/train_mst_extra/d_230...\n",
       "62273      w  ./save_temp/captcha_test/train_mst_extra/w_230...\n",
       "171848     8  ./save_temp/captcha_test/train_mst_extra/8_230...\n",
       "\n",
       "[86231 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e901ad6a-6785-4f59-beb0-4f9f11743173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 32s 48ms/step - loss: 0.2340 - accuracy: 0.9462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.23399831354618073, 'accuracy': 0.9462063312530518}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate loss and accuracy in test dataset\n",
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dac92-6d74-43c0-a888-141705a92ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a67f767-13aa-499b-856b-131296b73ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = './save_temp/captcha_test/model_save/model_final.h5'\n",
    "model.save(fmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d283cf92-f676-4f92-9d52-bd09925bad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9c30429-ceae-4a6a-9c69-482114af915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_model = load_model(fmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebd037-90ab-4868-b401-d8dadd4430a4",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b46fe48-feec-48ef-98eb-ebcd6a21edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MST_DIR_JPG_TEST = './save_temp/captcha_test/test_mst/jpg/'\n",
    "MST_DIR_PNG_TEST = './save_temp/captcha_test/test_mst/png/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a0133ba-2a04-46ab-af7c-22c2b7bfb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, fimg):\n",
    "    format_y = lambda y: ''.join(map(lambda x: chr(int(x)), y))\n",
    "    chars_ls = fimg.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "    res_chars = ''\n",
    "    y_pred_ls = []\n",
    "    y_pred_ls_all = []\n",
    "    for pos, c in enumerate(chars_ls):\n",
    "        chars_img = process_char(fimg, pos, num_chars=5, chop_wd=[0, -2, 2], chop_width=[0, 2])\n",
    "        y_pred_ls = []\n",
    "        for cimg in chars_img:\n",
    "            im = np.array([np.repeat(x, 3, axis=1) for x in cimg[0]], np.uint8)\n",
    "            im = np.array(im) / 255.0\n",
    "            y_pred = model.predict(np.array([im]), verbose=0)\n",
    "            am = tf.math.argmax(y_pred, axis=-1)\n",
    "            c = format_y(am[0])\n",
    "            y_pred_ls.append({'c': c, 'pc': y_pred[0][0][am][0][0]})\n",
    "\n",
    "        dft = pd.DataFrame.from_records(y_pred_ls)        \n",
    "        dft = dft.groupby('c')['pc'].agg(['count', 'max']).reset_index()\\\n",
    "                    .sort_values(by=['count'], ascending=False).head(2)\n",
    "        \n",
    "        # fix the ad hoc case r, h\n",
    "        if set(dft['c']) == set(['r', 'h']):\n",
    "            top_char = 'r'\n",
    "        else: \n",
    "            top_char = dft.sort_values(by=['max'], ascending=False).head(1).iloc[0][0]\n",
    "        \n",
    "        y_pred_ls_all.append(y_pred_ls)\n",
    "\n",
    "        res_chars += top_char\n",
    "    \n",
    "    return {\n",
    "        'match': (res_chars == chars_ls), \n",
    "        'predict': res_chars, \n",
    "        'input': chars_ls, \n",
    "        'params': y_pred_ls_all\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7d0f705-8010-4704-9035-c63f4f4928f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict folder\n",
    "files = glob.glob(os.path.join(MST_DIR_PNG_TEST, \"*.png\"))\n",
    "# files = glob.glob(os.path.join(MST_DIR_PNG, \"*.png\"))\n",
    "\n",
    "pred_captcha_dir = [predict_img(fn_model, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97fc19d6-2871-49cf-b415-8cf3e276feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_ls = [{'c': 'n', 'pc': 0.22}, {'c': 'h', 'pc': 0.22}]\n",
    "# dft = pd.DataFrame.from_records(y_pred_ls)\n",
    "# dft = dft.groupby('c')['pc'].agg(['count', 'max']).reset_index()\\\n",
    "#                     .sort_values(by=['count'], ascending=False).head(2)\n",
    "# if len(set(list(dft['c'])) - set(['n', 'h'])) == 0:\n",
    "#     print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd735e02-7892-4aec-8024-10f2fec7dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>predict</th>\n",
       "      <th>input</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>yk2ng</td>\n",
       "      <td>yk2ng</td>\n",
       "      <td>[[{'c': 'y', 'pc': 1.0}, {'c': 'y', 'pc': 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>gaawx</td>\n",
       "      <td>gaawx</td>\n",
       "      <td>[[{'c': 'g', 'pc': 1.0}, {'c': 'c', 'pc': 0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>ckpfr</td>\n",
       "      <td>ckpfr</td>\n",
       "      <td>[[{'c': 'c', 'pc': 0.9999969}, {'c': 'c', 'pc'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>6xx3g</td>\n",
       "      <td>6hx3g</td>\n",
       "      <td>[[{'c': '6', 'pc': 1.0}, {'c': '6', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>ekyy4</td>\n",
       "      <td>ekyy4</td>\n",
       "      <td>[[{'c': 'e', 'pc': 1.0}, {'c': 'e', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>543r3</td>\n",
       "      <td>543r3</td>\n",
       "      <td>[[{'c': '5', 'pc': 1.0}, {'c': '5', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>xx56d</td>\n",
       "      <td>xx56d</td>\n",
       "      <td>[[{'c': 'x', 'pc': 1.0}, {'c': 'x', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>nxpnh</td>\n",
       "      <td>nxpnh</td>\n",
       "      <td>[[{'c': 'n', 'pc': 1.0}, {'c': 'n', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>2y8ry</td>\n",
       "      <td>2y8ry</td>\n",
       "      <td>[[{'c': '2', 'pc': 1.0}, {'c': '2', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>bmbyr</td>\n",
       "      <td>bm3wr</td>\n",
       "      <td>[[{'c': 'b', 'pc': 0.9999943}, {'c': 'b', 'pc'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>mxh5r</td>\n",
       "      <td>mxh5r</td>\n",
       "      <td>[[{'c': 'm', 'pc': 0.9999901}, {'c': 'm', 'pc'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>3rbyy</td>\n",
       "      <td>3rbyy</td>\n",
       "      <td>[[{'c': '3', 'pc': 1.0}, {'c': '3', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>hpydp</td>\n",
       "      <td>hpydp</td>\n",
       "      <td>[[{'c': 'h', 'pc': 1.0}, {'c': 'h', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>7cyyn</td>\n",
       "      <td>7cyyn</td>\n",
       "      <td>[[{'c': '7', 'pc': 1.0}, {'c': '7', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>x5yx8</td>\n",
       "      <td>x5yx8</td>\n",
       "      <td>[[{'c': 'x', 'pc': 1.0}, {'c': 'x', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>8pkxr</td>\n",
       "      <td>8pkxr</td>\n",
       "      <td>[[{'c': '8', 'pc': 0.9758329}, {'c': '8', 'pc'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>44hwe</td>\n",
       "      <td>44hwe</td>\n",
       "      <td>[[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>yexmk</td>\n",
       "      <td>yexmk</td>\n",
       "      <td>[[{'c': 'y', 'pc': 1.0}, {'c': 'y', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>4p6pd</td>\n",
       "      <td>4p6pd</td>\n",
       "      <td>[[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>4w3pm</td>\n",
       "      <td>4wrpm</td>\n",
       "      <td>[[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>ke7wg</td>\n",
       "      <td>ke7wg</td>\n",
       "      <td>[[{'c': 'k', 'pc': 1.0}, {'c': 'k', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>efdaa</td>\n",
       "      <td>efdaa</td>\n",
       "      <td>[[{'c': 'e', 'pc': 1.0}, {'c': 'e', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>p22c2</td>\n",
       "      <td>p22c2</td>\n",
       "      <td>[[{'c': 'p', 'pc': 1.0}, {'c': 'p', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>pccp2</td>\n",
       "      <td>pccp2</td>\n",
       "      <td>[[{'c': 'p', 'pc': 1.0}, {'c': 'p', 'pc': 1.0}...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match predict  input                                             params\n",
       "0    True   yk2ng  yk2ng  [[{'c': 'y', 'pc': 1.0}, {'c': 'y', 'pc': 0.99...\n",
       "1    True   gaawx  gaawx  [[{'c': 'g', 'pc': 1.0}, {'c': 'c', 'pc': 0.93...\n",
       "2    True   ckpfr  ckpfr  [[{'c': 'c', 'pc': 0.9999969}, {'c': 'c', 'pc'...\n",
       "3   False   6xx3g  6hx3g  [[{'c': '6', 'pc': 1.0}, {'c': '6', 'pc': 1.0}...\n",
       "4    True   ekyy4  ekyy4  [[{'c': 'e', 'pc': 1.0}, {'c': 'e', 'pc': 1.0}...\n",
       "5    True   543r3  543r3  [[{'c': '5', 'pc': 1.0}, {'c': '5', 'pc': 1.0}...\n",
       "6    True   xx56d  xx56d  [[{'c': 'x', 'pc': 1.0}, {'c': 'x', 'pc': 1.0}...\n",
       "7    True   nxpnh  nxpnh  [[{'c': 'n', 'pc': 1.0}, {'c': 'n', 'pc': 1.0}...\n",
       "8    True   2y8ry  2y8ry  [[{'c': '2', 'pc': 1.0}, {'c': '2', 'pc': 1.0}...\n",
       "9   False   bmbyr  bm3wr  [[{'c': 'b', 'pc': 0.9999943}, {'c': 'b', 'pc'...\n",
       "10   True   mxh5r  mxh5r  [[{'c': 'm', 'pc': 0.9999901}, {'c': 'm', 'pc'...\n",
       "11   True   3rbyy  3rbyy  [[{'c': '3', 'pc': 1.0}, {'c': '3', 'pc': 1.0}...\n",
       "12   True   hpydp  hpydp  [[{'c': 'h', 'pc': 1.0}, {'c': 'h', 'pc': 1.0}...\n",
       "13   True   7cyyn  7cyyn  [[{'c': '7', 'pc': 1.0}, {'c': '7', 'pc': 1.0}...\n",
       "14   True   x5yx8  x5yx8  [[{'c': 'x', 'pc': 1.0}, {'c': 'x', 'pc': 1.0}...\n",
       "15   True   8pkxr  8pkxr  [[{'c': '8', 'pc': 0.9758329}, {'c': '8', 'pc'...\n",
       "16   True   44hwe  44hwe  [[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 1.0}...\n",
       "17   True   yexmk  yexmk  [[{'c': 'y', 'pc': 1.0}, {'c': 'y', 'pc': 1.0}...\n",
       "18   True   4p6pd  4p6pd  [[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 1.0}...\n",
       "19  False   4w3pm  4wrpm  [[{'c': '4', 'pc': 1.0}, {'c': '4', 'pc': 0.99...\n",
       "20   True   ke7wg  ke7wg  [[{'c': 'k', 'pc': 1.0}, {'c': 'k', 'pc': 1.0}...\n",
       "21   True   efdaa  efdaa  [[{'c': 'e', 'pc': 1.0}, {'c': 'e', 'pc': 1.0}...\n",
       "22   True   p22c2  p22c2  [[{'c': 'p', 'pc': 1.0}, {'c': 'p', 'pc': 1.0}...\n",
       "23   True   pccp2  pccp2  [[{'c': 'p', 'pc': 1.0}, {'c': 'p', 'pc': 1.0}..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(pred_captcha_dir)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7617092a-729d-4a35-a22d-bcb99c7dc675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     21\n",
       "False     3\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f1611b9-8d3d-4c21-acd8-4243d736cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>predict</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input predict  count\n",
       "0     3       b      1\n",
       "1     h       x      1\n",
       "2     r       3      1\n",
       "3     w       y      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_mis_match = lambda s1, s2: [{'input': c1, 'predict': c2} for c1, c2 in zip(s1, s2) if c1 != c2]\n",
    "failed_cases = df_pred[df_pred['match']==False].apply(lambda x: fn_mis_match(x['input'], \n",
    "                                                                             x['predict']), axis=1)\n",
    "failed_cases = list(itertools.chain.from_iterable(list(failed_cases)))\n",
    "df_failed_cases = pd.DataFrame(failed_cases).groupby(['input', 'predict']).size().reset_index(name='count')\\\n",
    "                        .sort_values('input')\n",
    "df_failed_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ef023-2181-44da-8dbd-98e48aeb4926",
   "metadata": {},
   "source": [
    "#### Detect the reason why failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "57ec52cf-2715-4b7a-aa50-e0f7588036b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[df_pred['match']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "fe60bdfd-65c9-4082-925c-a1546ab728dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[df_pred['match']==False].iloc[5], df_pred[df_pred['match']==False].iloc[5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "cf254a2f-5e4c-48e2-8158-cbd8037e88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[df_pred['match']==False].iloc[1], df_pred[df_pred['match']==False].iloc[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b41175-2619-4323-9016-d9b095d87088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e27ec8d-e20f-4ed0-bcc1-f700834678e3",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4110469f-2a4c-49af-bcfd-2f092487bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_noise(fimg):\n",
    "#     image = cv2.imread(fimg, cv2.IMREAD_GRAYSCALE)\n",
    "#     kernel = np.ones((2, 2), np.uint8)\n",
    "\n",
    "#     dilated_img = cv2.dilate(image, kernel, iterations=1)\n",
    "    \n",
    "#     # conver to black and white\n",
    "#     # dilated_img[dilated_img!=255] = 0\n",
    "\n",
    "    \n",
    "#     # remove lines or columns with all 0 to 255\n",
    "#     cols = [i for i in range(dilated_img.shape[1]) if not np.any(dilated_img[:, i])]\n",
    "#     rows = [i for i in range(dilated_img.shape[0]) if not np.any(dilated_img[i, :])]\n",
    "    \n",
    "#     dilated_img[:, cols] = 255\n",
    "#     dilated_img[rows, :] = 255\n",
    "    \n",
    "#     return dilated_img\n",
    "\n",
    "\n",
    "# def chop_window_sizes(arr, num_chars=5, chop_wd = [0, -2, -4, 2, 4], chop_width=[0]):\n",
    "    \n",
    "#     # Chop redundant background on left and right \n",
    "#     first =  min([x for x in [np.argmax(x!=255) for x in arr] if x!= 0])\n",
    "#     last = max([x for x in [arr.shape[1]-np.argmax(np.flip(x)!=255) for x in arr] if x!= arr.shape[1]])\n",
    "#     equal_size = (last - first) // num_chars\n",
    "    \n",
    "#     # Chop multi size\n",
    "#     arr_chars = []\n",
    "#     chop_size = [(x, x, w) for x in chop_wd for w in chop_width]   \n",
    "#     for i in range(num_chars):\n",
    "#         arr_chars.append([arr[:, max(0, i*equal_size+s[1]) : i*equal_size+equal_size+s[2]]\n",
    "#                                    for s in chop_size])\n",
    "    \n",
    "#     # padding for make equal width\n",
    "#     max_size = max([i.shape[1] for ch in arr_chars for i in ch]) + 4\n",
    "#     res_chars = []\n",
    "#     for ac in arr_chars:\n",
    "#         res_chars.append([np.column_stack((np.full((x.shape[0], (max_size - x.shape[1])//2), 255, np.uint8), x, \n",
    "#                                            np.full((x.shape[0], (max_size - x.shape[1])//2), 255, np.uint8))) \n",
    "#                                     for x in ac])\n",
    "\n",
    "#     return res_chars\n",
    "\n",
    "\n",
    "# def extract_contours_all(img_list):\n",
    "#     def extract_contours_(img):\n",
    "#         img = imutils.resize(img, width=32, height=32)\n",
    "#         img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "#         img = cv2.Canny(img, img.shape[0], img.shape[1])\n",
    "#         cnts = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         cnts = imutils.grab_contours(cnts)\n",
    "#         # cnts_sorted = sorted(cnts, key=lambda c: cv2.boundingRect(c)[0])\n",
    "#         cnts_sorted = cnts\n",
    "\n",
    "#         chars = []\n",
    "#         for i, c in enumerate(cnts_sorted):\n",
    "\n",
    "#             # compute the bounding box of the contour\n",
    "#             (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "#             if w >= 10 and h >= 10:\n",
    "#                 roi = img[y:y + h, x:x + w]\n",
    "#                 thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "#                 (tH, tW) = thresh.shape\n",
    "\n",
    "#                 # if the width is greater than the height, resize along the width dimension\n",
    "#                 rsw, rsh = 32, 32                \n",
    "#                 thresh = imutils.resize(thresh, width=rsw) if tW > tH else \\\n",
    "#                                 imutils.resize(thresh, height=rsh)\n",
    "#                 (tH, tW) = thresh.shape\n",
    "#                 dX = int(max(0, rsw - tW) / 2.0)\n",
    "#                 dY = int(max(0, rsh - tH) / 2.0)\n",
    "\n",
    "#                 # pad the image and force 32x32 dimensions\n",
    "#                 padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY, left=dX, right=dX, \n",
    "#                                             borderType=cv2.BORDER_CONSTANT,value=(0, 0, 0))\n",
    "#                 padded = cv2.resize(padded, (rsw, rsh))\n",
    "#                 padded = padded.astype(\"float32\")\n",
    "#                 padded = np.expand_dims(padded, axis=-1)\n",
    "#                 chars.append((padded, (x, y, w, h)))\n",
    "\n",
    "#         chars = sorted(chars, key=lambda c: c[1][2], reverse=True)\n",
    "#         return [chars[0]]\n",
    "    \n",
    "    \n",
    "#     def extract_contours_list_(img_list):\n",
    "#         chars_list = None\n",
    "#         for img in img_list:\n",
    "#             cts = extract_contours_(img)\n",
    "#             if len(cts) > 0:\n",
    "#                 chars_list = [cts[0]] if chars_list is None else chars_list + [cts[0]]\n",
    "#         # chars_list = sorted(chars_list, key=lambda c: c[1][2], reverse=True)\n",
    "        \n",
    "#         return chars_list\n",
    "\n",
    "        \n",
    "#     return extract_contours_list_(img_list)\n",
    "\n",
    "\n",
    "# def display_multi_2d(img_list, ncols=5, idepth=None):\n",
    "    \n",
    "#     nrows = sum([math.ceil(len(x) / ncols) for x in img_list])\n",
    "\n",
    "#     plt.figure()\n",
    "#     f, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "    \n",
    "#     iprev = 0\n",
    "#     for i in range(len(img_list)):\n",
    "#         for j in range(len(img_list[i])):\n",
    "#             irow = iprev + math.floor(j / ncols)\n",
    "#             icol = j - math.floor(j / ncols) * ncols\n",
    "#             img = img_list[i][j] if idepth is None else img_list[i][j][idepth]\n",
    "#             axes[icol].imshow(img) if nrows == 1 else axes[irow, icol].imshow(img)\n",
    "#         iprev = irow + 1\n",
    "    \n",
    "# def display_multi(img_list, ncols=5, idepth=None):\n",
    "    \n",
    "#     nrows = math.ceil(len(img_list) / ncols)\n",
    "\n",
    "#     plt.figure()\n",
    "#     f, axes = plt.subplots(nrows, ncols if nrows > 1 else len(img_list))\n",
    "#     for i in range(len(img_list)):\n",
    "#         irow, icol = math.floor(i/ncols), i%ncols\n",
    "#         img = img_list[i] if idepth is None else img_list[i][idepth]\n",
    "#         if len(img_list) == 1:\n",
    "#             axes.imshow(img)\n",
    "#         else:\n",
    "#             axes[icol].imshow(img) if nrows == 1 else axes[irow, icol].imshow(img)\n",
    "\n",
    "# def process_char(fimg, pos, num_chars=5, chop_wd = [0, -2, -4, 2, 4], chop_width=[0]):\n",
    "#     img_rn = remove_noise(fimg)\n",
    "#     chop_imgs = chop_window_sizes(img_rn, num_chars, chop_wd, chop_width)\n",
    "#     all_chars = extract_contours_all(chop_imgs[pos])\n",
    "\n",
    "#     return all_chars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
